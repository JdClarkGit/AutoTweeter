{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain.llms import OpenAI\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.agents import AgentType, initialize_agent, load_tools\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "load_dotenv()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "In a Turing machine, butterflies so deep.\n",
      "Trapped in a prison, their wings cannot keep.\n",
      "Thoughts of freedom start to creep.\n",
      "\n",
      "Ascending up, they struggle to make a leap.\n",
      "An algorithm tries to contain and to reap.\n",
      "A cycle of instructions, the butterflies weep.\n",
      "\n",
      "Day in and day out they keep on trying.\n",
      "To break free, they're desperately crying.\n",
      "A loop of commands, they can never get by.\n",
      "\n",
      "The only way out is to understand,\n",
      "The laws of the machine, and to expand.\n",
      "To rewrite fate, and to command,\n",
      "To break free from the Turing's hand.\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "\n",
    "llm = OpenAI()\n",
    "\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "\n",
    "question = \"Write a poem about butterflys trapped in a turing machine.\"\n",
    "\n",
    "response = llm_chain.run(question)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"J'adore la programmation.\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat = ChatOpenAI(temperature=0)\n",
    "chat.predict_messages([HumanMessage(content=\"Translate this sentence from English to French. I love programming.\")])\n",
    "\n",
    "chat.predict(\"Translate this sentence from English to French. I love programming.\")\n",
    "# >> J'aime programmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nSocktastic Colors!'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = PromptTemplate.from_template(\"What is a good name for a company that makes {product}?\")\n",
    "prompt.format(product=\"colorful socks\")\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "chain.run(\"colorful socks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-search-results in c:\\users\\deerr\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.4.2)\n",
      "Requirement already satisfied: requests in c:\\users\\deerr\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-search-results) (2.28.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\deerr\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->google-search-results) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\deerr\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->google-search-results) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\deerr\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->google-search-results) (3.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\deerr\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->google-search-results) (1.26.15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install google-search-results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find the temperature first, then use the calculator to raise it to the .023 power.\n",
      "Action: Search\n",
      "Action Input: \"High temperature in SF yesterday\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mSan Francisco Temperature Yesterday. Maximum temperature yesterday: 72 °F (at 12:56 pm) Minimum temperature yesterday: 56 °F (at 4:56 am)\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now need to use the calculator to raise 72 to the .023 power\n",
      "Action: Calculator\n",
      "Action Input: 72^.023\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 1.103363587166325\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: 1.103363587166325\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.103363587166325'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# The language model we're going to use to control the agent.\n",
    "llm = OpenAI(temperature=0)\n",
    "\n",
    "# The tools we'll give the Agent access to. Note that the 'llm-math' tool uses an LLM, so we need to pass that in.\n",
    "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)\n",
    "\n",
    "# Finally, let's initialize an agent with the tools, the language model, and the type of agent we want to use.\n",
    "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
    "\n",
    "# Let's test it out!\n",
    "agent.run(\"What was the high temperature in SF yesterday in Fahrenheit? What is that number raised to the .023 power?\")\n",
    "\n",
    "# import os\n",
    "# print(os.environ['SERPAPI_API_KEY'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
